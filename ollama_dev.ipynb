{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Ollama\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(\n",
    "    model=\"agent_pm\", callback_manager=CallbackManager([StreamingStdOutCallbackHandler()])\n",
    ")\n",
    "\n",
    "llm_json = Ollama(\n",
    "    model=\"agent_json_fixer\", callback_manager=CallbackManager([StreamingStdOutCallbackHandler()])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"tasks\": string  // The Project split into tasks, as a bulletpoint list.\n",
      "\t\"timeline\": string  // The time required for each task, as a bulletpoint list.\n",
      "\t\"deliverables\": string  // The Project deliverables with scope, as a bulletpoint list.\n",
      "\t\"team\": string  // The required Project team's skills and experience level, as a bulletpoint list.\n",
      "\t\"risks\": string  // The Project risks, as a bulletpoint list.\n",
      "\t\"budget\": string  // The budget for each task, as a bulletpoint list.\n",
      "\t\"metrics\": string  // The Project metrics, as a bulletpoint list.\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "tasks = ResponseSchema(\n",
    "        name=\"tasks\",\n",
    "        description=\"The Project split into tasks, as a bulletpoint list.\",\n",
    "    )\n",
    "timeline = ResponseSchema(\n",
    "        name=\"timeline\",\n",
    "        description=\"The time required for each task, as a bulletpoint list.\",\n",
    "    )\n",
    "deliverables =  ResponseSchema(\n",
    "        name=\"deliverables\",\n",
    "        description=\"The Project deliverables with scope, as a bulletpoint list.\",\n",
    "    )\n",
    "team = ResponseSchema(\n",
    "        name=\"team\",\n",
    "        description=\"The required Project team's skills and experience level, as a bulletpoint list.\",\n",
    "    )\n",
    "risks = ResponseSchema(\n",
    "        name=\"risks\",\n",
    "        description=\"The Project risks, as a bulletpoint list.\",\n",
    "    )\n",
    "budget = ResponseSchema(\n",
    "        name=\"budget\",\n",
    "        description=\"The budget for each task, as a bulletpoint list.\",\n",
    "    )\n",
    "metrics = ResponseSchema(\n",
    "        name=\"metrics\",\n",
    "        description=\"The Project metrics, as a bulletpoint list.\",\n",
    "    )\n",
    "output_parser = StructuredOutputParser.from_response_schemas([\n",
    "    tasks,\n",
    "    timeline,\n",
    "    deliverables,\n",
    "    team,\n",
    "    risks,\n",
    "    budget,\n",
    "    metrics,\n",
    "])\n",
    "\n",
    "response_format = output_parser.get_format_instructions()\n",
    "print(response_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"tasks\": [\n",
      "    \"Research and identify relevant external market data sources\",\n",
      "    \"Develop machine learning algorithms to integrate with firm's internal data\",\n",
      "    \"Train and validate the model using historical data\",\n",
      "    \"Implement the model into the firm's forecasting process\",\n",
      "    \"Monitor and evaluate the performance of the new forecasting system\",\n",
      "    \"Provide training and support to the firm's employees on the new system\"\n",
      "  ],\n",
      "  \"timeline\": [\n",
      "    \"Research and identify relevant external market data sources: 2 weeks\",\n",
      "    \"Develop machine learning algorithms to integrate with firm's internal data: 4 weeks\",\n",
      "    \"Train and validate the model using historical data: 6 weeks\",\n",
      "    \"Implement the model into the firm's forecasting process: 3 weeks\",\n",
      "    \"Monitor and evaluate the performance of the new forecasting system: ongoing\",\n",
      "    \"Provide training and support to the firm's employees on the new system: 2 weeks\"\n",
      "  ],\n",
      "  \"deliverables\": [\n",
      "    \"List of external market data sources identified\",\n",
      "    \"Machine learning algorithms developed and tested\",\n",
      "    \"Trained and validated model\",\n",
      "    \"Implemented forecasting process with improved accuracy\",\n",
      "    \"Ongoing monitoring and evaluation report\",\n",
      "    \"Training materials and support documentation\"\n",
      "  ],\n",
      "  \"team\": [\n",
      "    \"Project Manager with experience in managing complex projects\",\n",
      "    \"Data Scientist with expertise in machine learning and data analysis\",\n",
      "    \"Business Analyst with knowledge of the firm's internal processes\",\n",
      "    \"Training Specialist with experience in providing employee support\",\n",
      "    \"Marketing Specialist to identify relevant external market data sources\"\n",
      "  ],\n",
      "  \"risks\": [\n",
      "    \"Insufficient historical data for model training and validation\",\n",
      "    \"Difficulty in integrating machine learning algorithms with the firm's existing systems\",\n",
      "    \"Resistance to change from the firm's employees\",\n",
      "    \"Inadequate monitoring and evaluation of the new forecasting system\"\n",
      "  ],\n",
      "  \"budget\": [\n",
      "    \"Cost of external market data sources: $5000\",\n",
      "    \"Cost of machine learning algorithms development and testing: $10000\",\n",
      "    \"Cost of training and support materials: $2000\",\n",
      "    \"Ongoing monitoring and evaluation costs: $3000 per month\"\n",
      "  ],\n",
      "  \"metrics\": [\n",
      "    \"Improved accuracy of forecasting compared to current process\",\n",
      "    \"Increased efficiency in data analysis and decision-making\",\n",
      "    \"Reduced time and resources spent on manual forecasting\",\n",
      "    \"Higher level of employee satisfaction with new system\"\n",
      "  ]\n",
      "}\n",
      "```"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\\\n",
    "You have been given the following project brief. Identify and plan the key project tasks step by step.\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "Project Brief:\n",
    "{brief}\n",
    "\"\"\"\n",
    "\n",
    "brief = \"\"\"\\\n",
    "- The project is for a big multinational firm.\n",
    "- The firm employs about 10000 people.\n",
    "- The firm is grouped into a hierarchical structure, where each group specialises in a different industry or competency.\n",
    "- The firm is struggling to forecast its revenue accurately.\n",
    "- We are proposing to use machine learning an algorithms coupled with sourcing external market data to improve forecasting.\n",
    "- We aim to achieve a better accuracy than their current forecasting process.\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"brief\"],\n",
    "    partial_variables={\"format_instructions\": response_format}\n",
    ")\n",
    "\n",
    "_input = prompt.format_prompt(brief=brief)\n",
    "output_plan = llm(_input.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tasks': ['Research and identify relevant external market data sources', \"Develop machine learning algorithms to integrate with firm's internal data\", 'Train and validate the model using historical data', \"Implement the model into the firm's forecasting process\", 'Monitor and evaluate the performance of the new forecasting system', \"Provide training and support to the firm's employees on the new system\"], 'timeline': ['Research and identify relevant external market data sources: 2 weeks', \"Develop machine learning algorithms to integrate with firm's internal data: 4 weeks\", 'Train and validate the model using historical data: 6 weeks', \"Implement the model into the firm's forecasting process: 3 weeks\", 'Monitor and evaluate the performance of the new forecasting system: ongoing', \"Provide training and support to the firm's employees on the new system: 2 weeks\"], 'deliverables': ['List of external market data sources identified', 'Machine learning algorithms developed and tested', 'Trained and validated model', 'Implemented forecasting process with improved accuracy', 'Ongoing monitoring and evaluation report', 'Training materials and support documentation'], 'team': ['Project Manager with experience in managing complex projects', 'Data Scientist with expertise in machine learning and data analysis', \"Business Analyst with knowledge of the firm's internal processes\", 'Training Specialist with experience in providing employee support', 'Marketing Specialist to identify relevant external market data sources'], 'risks': ['Insufficient historical data for model training and validation', \"Difficulty in integrating machine learning algorithms with the firm's existing systems\", \"Resistance to change from the firm's employees\", 'Inadequate monitoring and evaluation of the new forecasting system'], 'budget': ['Cost of external market data sources: $5000', 'Cost of machine learning algorithms development and testing: $10000', 'Cost of training and support materials: $2000', 'Ongoing monitoring and evaluation costs: $3000 per month'], 'metrics': ['Improved accuracy of forecasting compared to current process', 'Increased efficiency in data analysis and decision-making', 'Reduced time and resources spent on manual forecasting', 'Higher level of employee satisfaction with new system']}\n"
     ]
    }
   ],
   "source": [
    "def parse_json_via_llm(string_to_parse):\n",
    "    try:\n",
    "        json_string = output_parser.parse(string_to_parse)\n",
    "    except Exception as e:\n",
    "        print(\"parsing failed, falling back to json formatter\")\n",
    "        json_template = \"\"\"\\\n",
    "        You have been given the following text. Convert it to correct JSON. If text is duplicated keep the most detailed version. No other text or information should be provided.\n",
    "\n",
    "        {format_instructions}\n",
    "\n",
    "        Text to convert to JSON:\n",
    "        {text_not_yet_json}\n",
    "        \"\"\"\n",
    "\n",
    "        prompt = PromptTemplate(\n",
    "            template=json_template,\n",
    "            input_variables=[\"text_not_yet_json\"],\n",
    "            partial_variables={\"format_instructions\": response_format}\n",
    "        )\n",
    "\n",
    "        _input = prompt.format_prompt(text_not_yet_json=string_to_parse)\n",
    "        json_output = llm_json(_input.to_string())\n",
    "        json_string = output_parser.parse(json_output)\n",
    "    return json_string\n",
    "\n",
    "json_string = parse_json_via_llm(output_plan)\n",
    "print(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the detailed step-by-step plans for each task in the project brief:\n",
      "\n",
      "Task 1: Research and identify relevant external market data sources\n",
      "\n",
      "* Step 1: Identify the industries or competencies that the firm specialises in.\n",
      "\t+ Step 1.1: Create a list of potential external market data sources for each industry or competency.\n",
      "\t+ Step 1.2: Evaluate the relevance and accuracy of each source based on factors such as data quality, coverage, and frequency.\n",
      "* Step 2: Shortlist the most relevant external market data sources for further analysis.\n",
      "\t+ Step 2.1: Analyze the shortlisted sources to determine their suitability for the project.\n",
      "\t+ Step 2.2: Select the best-suited sources based on factors such as data quality, coverage, and frequency.\n",
      "* Step 3: Develop a plan for collecting and integrating the selected external market data sources with the firm's internal data.\n",
      "\t+ Step 3.1: Determine the format and structure of the external data sources.\n",
      "\t+ Step 3.2: Develop a plan for data integration, including data cleaning, transformation, and aggregation.\n",
      "* Step 4: Implement the plan for collecting and integrating external market data sources with the firm's internal data.\n",
      "\t+ Step 4.1: Collect and integrate the selected external data sources with the firm's internal data.\n",
      "\t+ Step 4.2: Monitor and evaluate the performance of the integrated data.\n",
      "\n",
      "Task 2: Develop machine learning algorithms to integrate with firm's internal data\n",
      "\n",
      "* Step 1: Determine the type of machine learning algorithm best suited for the project based on factors such as data complexity, volume, and velocity.\n",
      "\t+ Step 1.1: Research and evaluate different types of machine learning algorithms, including supervised, unsupervised, and reinforcement learning.\n",
      "\t+ Step 1.2: Select the most appropriate algorithm based on the project requirements.\n",
      "* Step 2: Develop a plan for integrating the selected machine learning algorithm with the firm's internal data.\n",
      "\t+ Step 2.1: Determine the format and structure of the firm's internal data.\n",
      "\t+ Step 2.2: Develop a plan for data integration, including data cleaning, transformation, and aggregation.\n",
      "* Step 3: Implement the plan for integrating the machine learning algorithm with the firm's internal data.\n",
      "\t+ Step 3.1: Integrate the selected machine learning algorithm with the firm's internal data.\n",
      "\t+ Step 3.2: Monitor and evaluate the performance of the integrated algorithm.\n",
      "\n",
      "Task 3: Train and validate the model using historical data\n",
      "\n",
      "* Step 1: Determine the historical data required for training and validation.\n",
      "\t+ Step 1.1: Identify the relevant historical data sources.\n",
      "\t+ Step 1.2: Evaluate the quality and relevance of each historical data source.\n",
      "* Step 2: Prepare the historical data for training and validation.\n",
      "\t+ Step 2.1: Clean and transform the historical data into a format suitable for training and validation.\n",
      "\t+ Step 2.2: Split the historical data into training and validation sets.\n",
      "* Step 3: Train the machine learning model using the historical data.\n",
      "\t+ Step 3.1: Use the training set to train the selected machine learning algorithm.\n",
      "\t+ Step 3.2: Evaluate the performance of the trained model using the validation set.\n",
      "* Step 4: Fine-tune the model as required based on the performance evaluation.\n",
      "\t+ Step 4.1: Identify areas for improvement in the trained model.\n",
      "\t+ Step 4.2: Make necessary adjustments to the model and retrain it using the historical data.\n",
      "\n",
      "Task 4: Implement the model into the firm's forecasting process\n",
      "\n",
      "* Step 1: Determine the best way to integrate the machine learning model into the firm's existing forecasting process.\n",
      "\t+ Step 1.1: Evaluate the current forecasting process and identify areas for improvement.\n",
      "\t+ Step 1.2: Determine how the machine learning model can complement or replace existing forecasting methods.\n",
      "* Step 2: Implement the machine learning model into the firm's forecasting process.\n",
      "\t+ Step 2.1: Integrate the trained machine learning model with the firm's existing forecasting tools and processes.\n",
      "\t+ Step 2.2: Monitor and evaluate the performance of the integrated model.\n",
      "* Step 3: Provide training and support to the firm's employees on the new system.\n",
      "\t+ Step 3.1: Develop a comprehensive training program for the firm's employees.\n",
      "\t+ Step 3.2: Provide ongoing support and assistance to ensure successful adoption of the new system.\n",
      "\n",
      "Task 5: Monitor and evaluate the performance of the new forecasting system\n",
      "\n",
      "* Step 1: Determine the key performance indicators (KPIs) for evaluating the success of the new forecasting system.\n",
      "\t+ Step 1.1: Identify the relevant KPIs based on factors such as accuracy, precision, and timeliness.\n",
      "\t+ Step 1.2: Develop a plan for monitoring and evaluating the performance of the new forecasting system.\n",
      "* Step 2: Monitor and evaluate the performance of the new forecasting system using the KPIs.\n",
      "\t+ Step 2.1: Collect and analyze data on the performance of the new forecasting system.\n",
      "\t+ Step 2.2: Compare the performance of the new forecasting system with the current forecasting process.\n",
      "* Step 3: Make adjustments to the machine learning model or the forecasting process as required based on the evaluation results.\n",
      "\t+ Step 3.1: Identify areas for improvement in the machine learning model or the forecasting process.\n",
      "\t+ Step 3.2: Make necessary adjustments and retrain the machine learning model using the updated data.\n",
      "\n",
      "Task 6: Provide training and support to the firm's employees on the new system\n",
      "\n",
      "* Step 1: Develop a comprehensive training program for the firm's employees.\n",
      "\t+ Step 1.1: Identify the key concepts and skills required for successful use of the new forecasting system.\n",
      "\t+ Step 1.2: Create a detailed training plan that covers all aspects of the new system.\n",
      "* Step 2: Provide ongoing support and assistance to ensure successful adoption of the new system.\n",
      "\t+ Step 2.1: Offer regular training sessions and workshops for employees.\n",
      "\t+ Step 2.2: Provide on-demand support and assistance as required.\n",
      "\n",
      "By following these detailed step-by-step plans, you can ensure that each task in the project brief is completed successfully and within the required timeframe."
     ]
    }
   ],
   "source": [
    "template = \"\"\"\\\n",
    "Given the following project brief, and a list of tasks to solve for the brief. Take each task in the list and plan it step by step in detail.\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "Project Brief:\n",
    "{brief}\n",
    "\n",
    "Tasks:\n",
    "{tasks}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"brief\"],\n",
    "    partial_variables={\"format_instructions\": response_format}\n",
    ")\n",
    "\n",
    "_input = prompt.format_prompt(brief=brief, tasks=json_string['tasks'])\n",
    "task_plan = llm(_input.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsing failed, falling back to json formatter\n",
      "```json\n",
      "{\n",
      "    \"tasks\": [\n",
      "        {\n",
      "            \"name\": \"Research and identify relevant external market data sources\",\n",
      "            \"steps\": [\n",
      "                {\n",
      "                    \"step\": \"Step 1\",\n",
      "                    \"subSteps\": [\n",
      "                        {\n",
      "                            \"name\": \"Identify the industries or competencies that the firm specialises in\",\n",
      "                            \"description\": \"Create a list of potential external market data sources for each industry or competency.\"\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"Evaluate the relevance and accuracy of each source based on factors such as data quality, coverage, and frequency.\",\n",
      "                            \"description\": \"Shortlist the most relevant external market data sources for further analysis.\"\n",
      "                        }\n",
      "                    ]\n",
      "                },\n",
      "                {\n",
      "                    \"step\": \"Step 2\",\n",
      "                    \"subSteps\": [\n",
      "                        {\n",
      "                            \"name\": \"Analyze the shortlisted sources to determine their suitability for the project.\",\n",
      "                            \"description\": \"Develop a plan for data integration, including data cleaning, transformation, and aggregation.\"\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"Select the best-suited sources based on factors such as data quality, coverage, and frequency.\",\n",
      "                            \"description\": \"Implement the plan for collecting and integrating the selected external data sources with the firm's internal data.\"\n",
      "                        }\n",
      "                    ]\n",
      "                },\n",
      "                {\n",
      "                    \"step\": \"Step 3\",\n",
      "                    \"subSteps\": [\n",
      "                        {\n",
      "                            \"name\": \"Determine the format and structure of the external data sources.\",\n",
      "                            \"description\": \"Monitor and evaluate the performance of the integrated data.\"\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"Develop a plan for data integration, including data cleaning, transformation, and aggregation.\",\n",
      "                 analyzer: \"Step 2\"\n",
      "                        }\n",
      "                    ]\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"Develop machine learning algorithms to integrate with firm's internal data\",\n",
      "            \"steps\": [\n",
      "                {\n",
      "                    \"step\": \"Step 1\",\n",
      "                    \"subSteps\": [\n",
      "                        {\n",
      "                            \"name\": \"Determine the type of machine learning algorithm best suited for the project based on factors such as data complexity, volume, and velocity.\",\n",
      "                            \"description\": \"Research and evaluate different types of machine learning algorithms, including supervised, unsupervised, and reinforcement learning.\"\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"Select the most appropriate algorithm based on the project requirements.\",\n",
      "                            \"description\": \"Develop a plan for integrating the selected machine learning algorithm with the firm's internal data.\"\n",
      "                        }\n",
      "                    ]\n",
      "                },\n",
      "                {\n",
      "                    \"step\": \"Step 2\",\n",
      "                    \"subSteps\": [\n",
      "                        {\n",
      "                            \"name\": \"Determine the format and structure of the firm's internal data.\",\n",
      "                            \"description\": \"Develop a plan for data integration, including data cleaning, transformation, and aggregation.\"\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"Integrate the selected machine learning algorithm with the firm's internal data.\",\n",
      "                            \"description\": \"Monitor and evaluate the performance of the integrated algorithm.\"\n",
      "                        }\n",
      "                    ]\n",
      "                },\n",
      "                {\n",
      "                    \"step\": \"Step 3\",\n",
      "                    \"subSteps\": [\n",
      "                        {\n",
      "                            \"name\": \"Train the machine learning model using the historical data.\",\n",
      "                            \"description\": \"Evaluate the performance of the trained model using the validation set.\"\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"Fine-tune the model as required based on the performance evaluation.\",\n",
      "                            \"description\": \"Integrate the trained machine learning model with the firm's internal data.\"\n",
      "                        }\n",
      "                    ]\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"Train and validate the model using historical data\",\n",
      "            \"steps\": [\n",
      "                {\n",
      "                    \"step\": \"Step 1\",\n",
      "                    \"subSteps\": [\n",
      "                        {\n",
      "                            \"name\": \"Determine the historical data required for training and validation.\",\n",
      "                            \"description\": \"Evaluate the quality and relevance of each historical data source.\"\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"Prepare the historical data for training and validation.\",\n",
      "                            \"description\": \"Split the historical data into training and validation sets.\"\n",
      "                        }\n",
      "                    ]\n",
      "                },\n",
      "                {\n",
      "                    \"step\": \"Step 2\",\n",
      "                    \"subSteps\": [\n",
      "                        {\n",
      "                            \"name\": \"Train the machine learning model using the training set.\",\n",
      "                            \"description\": \"Evaluate the performance of the trained model using the validation set.\"\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"Fine-tune the model as required based on the performance evaluation.\",\n",
      "                            \"description\": \"Integrate the trained machine learning model with the firm's internal data.\"\n",
      "                        }\n",
      "                    ]\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"Implement the model into the firm's forecasting process\",\n",
      "            \"steps\": [\n",
      "                {\n",
      "                    \"step\": \"Step 1\",\n",
      "                    \"subSteps\": [\n",
      "                        {\n",
      "                            \"name\": \"Determine the best way to integrate the machine learning model into the firm's existing forecasting process.\",\n",
      "                            \"description\": \"Evaluate the current forecasting process and identify areas for improvement.\"\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"Determine how the machine learning model can complement or replace existing forecasting methods.\",\n",
      "                            \"description\": \"Develop a plan for integrating the selected machine learning algorithm with the firm's existing forecasting tools and processes.\"\n",
      "                        }\n",
      "                    ]\n",
      "                },\n",
      "                {\n",
      "                    \"step\": \"Step 2\",\n",
      "                    \"subSteps\": [\n",
      "                        {\n",
      "                            \"name\": \"Integrate the trained machine learning model with the firm's existing forecasting tools and processes.\",\n",
      "                            \"description\": \"Monitor and evaluate the performance of the integrated model.\"\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"Provide training and support to the firm's employees on the new system.\",\n",
      "                            \"description\": \"Develop a comprehensive training program for the firm's employees.\"\n",
      "                        }\n",
      "                    ]\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"Monitor and evaluate the performance of the new forecasting system\",\n",
      "            \"steps\": [\n",
      "                {\n",
      "                    \"step\": \"Step 1\",\n",
      "                    \"subSteps\": [\n",
      "                        {\n",
      "                            \"name\": \"Determine the key performance indicators (KPIs) for evaluating the success of the new forecasting system.\",\n",
      "                            \"description\": \"Identify the relevant KPIs based on factors such as accuracy, precision, and timeliness.\"\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"Develop a plan for monitoring and evaluating the performance of the new forecasting system.\",\n",
      "                            \"description\": \"Collect and analyze data on the performance of the new forecasting system.\"\n",
      "                        }\n",
      "                    ]\n",
      "                },\n",
      "                {\n",
      "                    \"step\": \"Step 2\",\n",
      "                    \"subSteps\": [\n",
      "                        {\n",
      "                            \"name\": \"Monitor and evaluate the"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/share/virtualenvs/llm_agent_team-CchbYHaz/lib/python3.11/site-packages/langchain/output_parsers/json.py:163\u001b[0m, in \u001b[0;36mparse_and_check_json_markdown\u001b[0;34m(text, expected_keys)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     json_obj \u001b[39m=\u001b[39m parse_json_markdown(text)\n\u001b[1;32m    164\u001b[0m \u001b[39mexcept\u001b[39;00m json\u001b[39m.\u001b[39mJSONDecodeError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/llm_agent_team-CchbYHaz/lib/python3.11/site-packages/langchain/output_parsers/json.py:145\u001b[0m, in \u001b[0;36mparse_json_markdown\u001b[0;34m(json_string, parser)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[39m# Parse the JSON string into a Python dictionary\u001b[39;00m\n\u001b[0;32m--> 145\u001b[0m parsed \u001b[39m=\u001b[39m parser(json_str)\n\u001b[1;32m    147\u001b[0m \u001b[39mreturn\u001b[39;00m parsed\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m parse_float \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_pairs_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_decoder\u001b[39m.\u001b[39;49mdecode(s)\n\u001b[1;32m    347\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[39mcontaining a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw_decode(s, idx\u001b[39m=\u001b[39;49m_w(s, \u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mend())\n\u001b[1;32m    338\u001b[0m end \u001b[39m=\u001b[39m _w(s, end)\u001b[39m.\u001b[39mend()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[39mraise\u001b[39;00m JSONDecodeError(\u001b[39m\"\u001b[39m\u001b[39mExpecting value\u001b[39m\u001b[39m\"\u001b[39m, s, err\u001b[39m.\u001b[39mvalue) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[39mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32m/Users/jurgenstrydom/Projects/llm_agent_team/ollama_dev.ipynb Cell 7\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jurgenstrydom/Projects/llm_agent_team/ollama_dev.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jurgenstrydom/Projects/llm_agent_team/ollama_dev.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     json_string \u001b[39m=\u001b[39m output_parser\u001b[39m.\u001b[39;49mparse(string_to_parse)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jurgenstrydom/Projects/llm_agent_team/ollama_dev.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/llm_agent_team-CchbYHaz/lib/python3.11/site-packages/langchain/output_parsers/structured.py:96\u001b[0m, in \u001b[0;36mStructuredOutputParser.parse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     95\u001b[0m expected_keys \u001b[39m=\u001b[39m [rs\u001b[39m.\u001b[39mname \u001b[39mfor\u001b[39;00m rs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresponse_schemas]\n\u001b[0;32m---> 96\u001b[0m \u001b[39mreturn\u001b[39;00m parse_and_check_json_markdown(text, expected_keys)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/llm_agent_team-CchbYHaz/lib/python3.11/site-packages/langchain/output_parsers/json.py:165\u001b[0m, in \u001b[0;36mparse_and_check_json_markdown\u001b[0;34m(text, expected_keys)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[39mexcept\u001b[39;00m json\u001b[39m.\u001b[39mJSONDecodeError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 165\u001b[0m     \u001b[39mraise\u001b[39;00m OutputParserException(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGot invalid JSON object. Error: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    166\u001b[0m \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m expected_keys:\n",
      "\u001b[0;31mOutputParserException\u001b[0m: Got invalid JSON object. Error: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/jurgenstrydom/Projects/llm_agent_team/ollama_dev.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jurgenstrydom/Projects/llm_agent_team/ollama_dev.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m json_task_string \u001b[39m=\u001b[39m parse_json_via_llm(task_plan)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jurgenstrydom/Projects/llm_agent_team/ollama_dev.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(json_task_string)\n",
      "\u001b[1;32m/Users/jurgenstrydom/Projects/llm_agent_team/ollama_dev.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jurgenstrydom/Projects/llm_agent_team/ollama_dev.ipynb#X12sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     prompt \u001b[39m=\u001b[39m PromptTemplate(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jurgenstrydom/Projects/llm_agent_team/ollama_dev.ipynb#X12sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m         template\u001b[39m=\u001b[39mjson_template,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jurgenstrydom/Projects/llm_agent_team/ollama_dev.ipynb#X12sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m         input_variables\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mtext_not_yet_json\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jurgenstrydom/Projects/llm_agent_team/ollama_dev.ipynb#X12sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m         partial_variables\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mformat_instructions\u001b[39m\u001b[39m\"\u001b[39m: response_format}\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jurgenstrydom/Projects/llm_agent_team/ollama_dev.ipynb#X12sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jurgenstrydom/Projects/llm_agent_team/ollama_dev.ipynb#X12sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     _input \u001b[39m=\u001b[39m prompt\u001b[39m.\u001b[39mformat_prompt(text_not_yet_json\u001b[39m=\u001b[39mstring_to_parse)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jurgenstrydom/Projects/llm_agent_team/ollama_dev.ipynb#X12sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     json_output \u001b[39m=\u001b[39m llm_json(_input\u001b[39m.\u001b[39;49mto_string())\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jurgenstrydom/Projects/llm_agent_team/ollama_dev.ipynb#X12sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     json_string \u001b[39m=\u001b[39m output_parser\u001b[39m.\u001b[39mparse(json_output)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jurgenstrydom/Projects/llm_agent_team/ollama_dev.ipynb#X12sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mreturn\u001b[39;00m json_string\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/llm_agent_team-CchbYHaz/lib/python3.11/site-packages/langchain/llms/base.py:876\u001b[0m, in \u001b[0;36mBaseLLM.__call__\u001b[0;34m(self, prompt, stop, callbacks, tags, metadata, **kwargs)\u001b[0m\n\u001b[1;32m    869\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(prompt, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    870\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    871\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mArgument `prompt` is expected to be a string. Instead found \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    872\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(prompt)\u001b[39m}\u001b[39;00m\u001b[39m. If you want to run the LLM on multiple prompts, use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    873\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`generate` instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    874\u001b[0m     )\n\u001b[1;32m    875\u001b[0m \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 876\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(\n\u001b[1;32m    877\u001b[0m         [prompt],\n\u001b[1;32m    878\u001b[0m         stop\u001b[39m=\u001b[39;49mstop,\n\u001b[1;32m    879\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    880\u001b[0m         tags\u001b[39m=\u001b[39;49mtags,\n\u001b[1;32m    881\u001b[0m         metadata\u001b[39m=\u001b[39;49mmetadata,\n\u001b[1;32m    882\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    883\u001b[0m     )\n\u001b[1;32m    884\u001b[0m     \u001b[39m.\u001b[39mgenerations[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\n\u001b[1;32m    885\u001b[0m     \u001b[39m.\u001b[39mtext\n\u001b[1;32m    886\u001b[0m )\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/llm_agent_team-CchbYHaz/lib/python3.11/site-packages/langchain/llms/base.py:656\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    642\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    643\u001b[0m         )\n\u001b[1;32m    644\u001b[0m     run_managers \u001b[39m=\u001b[39m [\n\u001b[1;32m    645\u001b[0m         callback_manager\u001b[39m.\u001b[39mon_llm_start(\n\u001b[1;32m    646\u001b[0m             dumpd(\u001b[39mself\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    654\u001b[0m         )\n\u001b[1;32m    655\u001b[0m     ]\n\u001b[0;32m--> 656\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate_helper(\n\u001b[1;32m    657\u001b[0m         prompts, stop, run_managers, \u001b[39mbool\u001b[39;49m(new_arg_supported), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    658\u001b[0m     )\n\u001b[1;32m    659\u001b[0m     \u001b[39mreturn\u001b[39;00m output\n\u001b[1;32m    660\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(missing_prompts) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/llm_agent_team-CchbYHaz/lib/python3.11/site-packages/langchain/llms/base.py:544\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    542\u001b[0m     \u001b[39mfor\u001b[39;00m run_manager \u001b[39min\u001b[39;00m run_managers:\n\u001b[1;32m    543\u001b[0m         run_manager\u001b[39m.\u001b[39mon_llm_error(e)\n\u001b[0;32m--> 544\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    545\u001b[0m flattened_outputs \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mflatten()\n\u001b[1;32m    546\u001b[0m \u001b[39mfor\u001b[39;00m manager, flattened_output \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(run_managers, flattened_outputs):\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/llm_agent_team-CchbYHaz/lib/python3.11/site-packages/langchain/llms/base.py:531\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_generate_helper\u001b[39m(\n\u001b[1;32m    522\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    523\u001b[0m     prompts: List[\u001b[39mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    527\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    528\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[1;32m    529\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    530\u001b[0m         output \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 531\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(\n\u001b[1;32m    532\u001b[0m                 prompts,\n\u001b[1;32m    533\u001b[0m                 stop\u001b[39m=\u001b[39;49mstop,\n\u001b[1;32m    534\u001b[0m                 \u001b[39m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[1;32m    535\u001b[0m                 run_manager\u001b[39m=\u001b[39;49mrun_managers[\u001b[39m0\u001b[39;49m] \u001b[39mif\u001b[39;49;00m run_managers \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    536\u001b[0m                 \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    537\u001b[0m             )\n\u001b[1;32m    538\u001b[0m             \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    539\u001b[0m             \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(prompts, stop\u001b[39m=\u001b[39mstop)\n\u001b[1;32m    540\u001b[0m         )\n\u001b[1;32m    541\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    542\u001b[0m         \u001b[39mfor\u001b[39;00m run_manager \u001b[39min\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/llm_agent_team-CchbYHaz/lib/python3.11/site-packages/langchain/llms/ollama.py:220\u001b[0m, in \u001b[0;36mOllama._generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m generations \u001b[39m=\u001b[39m []\n\u001b[1;32m    219\u001b[0m \u001b[39mfor\u001b[39;00m prompt \u001b[39min\u001b[39;00m prompts:\n\u001b[0;32m--> 220\u001b[0m     final_chunk \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_stream_with_aggregation(\n\u001b[1;32m    221\u001b[0m         prompt,\n\u001b[1;32m    222\u001b[0m         stop\u001b[39m=\u001b[39;49mstop,\n\u001b[1;32m    223\u001b[0m         run_manager\u001b[39m=\u001b[39;49mrun_manager,\n\u001b[1;32m    224\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    225\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    226\u001b[0m     )\n\u001b[1;32m    227\u001b[0m     generations\u001b[39m.\u001b[39mappend([final_chunk])\n\u001b[1;32m    228\u001b[0m \u001b[39mreturn\u001b[39;00m LLMResult(generations\u001b[39m=\u001b[39mgenerations)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/llm_agent_team-CchbYHaz/lib/python3.11/site-packages/langchain/llms/ollama.py:156\u001b[0m, in \u001b[0;36m_OllamaCommon._stream_with_aggregation\u001b[0;34m(self, prompt, stop, run_manager, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_stream_with_aggregation\u001b[39m(\n\u001b[1;32m    148\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    149\u001b[0m     prompt: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    154\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m GenerationChunk:\n\u001b[1;32m    155\u001b[0m     final_chunk: Optional[GenerationChunk] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 156\u001b[0m     \u001b[39mfor\u001b[39;49;00m stream_resp \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_stream(prompt, stop, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs):\n\u001b[1;32m    157\u001b[0m         \u001b[39mif\u001b[39;49;00m stream_resp:\n\u001b[1;32m    158\u001b[0m             chunk \u001b[39m=\u001b[39;49m _stream_response_to_generation_chunk(stream_resp)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/llm_agent_team-CchbYHaz/lib/python3.11/site-packages/requests/models.py:865\u001b[0m, in \u001b[0;36mResponse.iter_lines\u001b[0;34m(self, chunk_size, decode_unicode, delimiter)\u001b[0m\n\u001b[1;32m    856\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Iterates over the response data, one line at a time.  When\u001b[39;00m\n\u001b[1;32m    857\u001b[0m \u001b[39mstream=True is set on the request, this avoids reading the\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[39mcontent at once into memory for large responses.\u001b[39;00m\n\u001b[1;32m    859\u001b[0m \n\u001b[1;32m    860\u001b[0m \u001b[39m.. note:: This method is not reentrant safe.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    863\u001b[0m pending \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 865\u001b[0m \u001b[39mfor\u001b[39;49;00m chunk \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter_content(\n\u001b[1;32m    866\u001b[0m     chunk_size\u001b[39m=\u001b[39;49mchunk_size, decode_unicode\u001b[39m=\u001b[39;49mdecode_unicode\n\u001b[1;32m    867\u001b[0m ):\n\u001b[1;32m    869\u001b[0m     \u001b[39mif\u001b[39;49;00m pending \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m:\n\u001b[1;32m    870\u001b[0m         chunk \u001b[39m=\u001b[39;49m pending \u001b[39m+\u001b[39;49m chunk\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/llm_agent_team-CchbYHaz/lib/python3.11/site-packages/requests/utils.py:571\u001b[0m, in \u001b[0;36mstream_decode_response_unicode\u001b[0;34m(iterator, r)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    570\u001b[0m decoder \u001b[39m=\u001b[39m codecs\u001b[39m.\u001b[39mgetincrementaldecoder(r\u001b[39m.\u001b[39mencoding)(errors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mreplace\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 571\u001b[0m \u001b[39mfor\u001b[39;49;00m chunk \u001b[39min\u001b[39;49;00m iterator:\n\u001b[1;32m    572\u001b[0m     rv \u001b[39m=\u001b[39;49m decoder\u001b[39m.\u001b[39;49mdecode(chunk)\n\u001b[1;32m    573\u001b[0m     \u001b[39mif\u001b[39;49;00m rv:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/llm_agent_team-CchbYHaz/lib/python3.11/site-packages/requests/models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw, \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    815\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 816\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw\u001b[39m.\u001b[39mstream(chunk_size, decode_content\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    817\u001b[0m     \u001b[39mexcept\u001b[39;00m ProtocolError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    818\u001b[0m         \u001b[39mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/llm_agent_team-CchbYHaz/lib/python3.11/site-packages/urllib3/response.py:624\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    609\u001b[0m \u001b[39mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[1;32m    610\u001b[0m \u001b[39m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[39m    'content-encoding' header.\u001b[39;00m\n\u001b[1;32m    622\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    623\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunked \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupports_chunked_reads():\n\u001b[0;32m--> 624\u001b[0m     \u001b[39mfor\u001b[39;49;00m line \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread_chunked(amt, decode_content\u001b[39m=\u001b[39;49mdecode_content):\n\u001b[1;32m    625\u001b[0m         \u001b[39myield\u001b[39;49;00m line\n\u001b[1;32m    626\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/llm_agent_team-CchbYHaz/lib/python3.11/site-packages/urllib3/response.py:828\u001b[0m, in \u001b[0;36mHTTPResponse.read_chunked\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    825\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    827\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 828\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_chunk_length()\n\u001b[1;32m    829\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunk_left \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    830\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/llm_agent_team-CchbYHaz/lib/python3.11/site-packages/urllib3/response.py:758\u001b[0m, in \u001b[0;36mHTTPResponse._update_chunk_length\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    756\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunk_left \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    757\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 758\u001b[0m line \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp\u001b[39m.\u001b[39mfp\u001b[39m.\u001b[39mreadline()\n\u001b[1;32m    759\u001b[0m line \u001b[39m=\u001b[39m line\u001b[39m.\u001b[39msplit(\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m;\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    760\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    707\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "json_task_string = parse_json_via_llm(task_plan)\n",
    "print(json_task_string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_agent_team-CchbYHaz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
